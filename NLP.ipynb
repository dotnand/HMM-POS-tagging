{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kishorn\\AppData\\Local\\Continuum\\anaconda\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_profiling import ProfileReport\n",
    "%matplotlib inline\n",
    "from stop_words import get_stop_words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Read the Womens Clothing E-Commerce Reviews.csv file and set it as a Dataframe called clothing_reviews. Check the head, info, and describe methods on the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_reviews=pd.read_csv(\"Womens Clothing E-Commerce Reviews.csv\",index_col=False)\n",
    "column_contain=['Clothing ID','Age','Title','Review Text','Rating','Recommended IND','Positive Feedback Count','Division Name','Department Name','Class Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clothing ID  Age                    Title  \\\n",
       "0          767   33                      NaN   \n",
       "1         1080   34                      NaN   \n",
       "2         1077   60  Some major design flaws   \n",
       "3         1049   50         My favorite buy!   \n",
       "4          847   47         Flattering shirt   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0       Initmates        Intimate  Intimates  \n",
       "1                        4         General         Dresses    Dresses  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clothing_reviews=pd.DataFrame(data=clothing_reviews,columns=column_contain)\n",
    "clothing_reviews.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23486 entries, 0 to 23485\n",
      "Data columns (total 10 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   Clothing ID              23486 non-null  int64 \n",
      " 1   Age                      23486 non-null  int64 \n",
      " 2   Title                    19676 non-null  object\n",
      " 3   Review Text              22641 non-null  object\n",
      " 4   Rating                   23486 non-null  int64 \n",
      " 5   Recommended IND          23486 non-null  int64 \n",
      " 6   Positive Feedback Count  23486 non-null  int64 \n",
      " 7   Division Name            23472 non-null  object\n",
      " 8   Department Name          23472 non-null  object\n",
      " 9   Class Name               23472 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "clothing_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23486.000000</td>\n",
       "      <td>23486.000000</td>\n",
       "      <td>23486.000000</td>\n",
       "      <td>23486.000000</td>\n",
       "      <td>23486.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>918.118709</td>\n",
       "      <td>43.198544</td>\n",
       "      <td>4.196032</td>\n",
       "      <td>0.822362</td>\n",
       "      <td>2.535936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>203.298980</td>\n",
       "      <td>12.279544</td>\n",
       "      <td>1.110031</td>\n",
       "      <td>0.382216</td>\n",
       "      <td>5.702202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>861.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>936.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1078.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1205.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>122.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Clothing ID           Age        Rating  Recommended IND  \\\n",
       "count  23486.000000  23486.000000  23486.000000     23486.000000   \n",
       "mean     918.118709     43.198544      4.196032         0.822362   \n",
       "std      203.298980     12.279544      1.110031         0.382216   \n",
       "min        0.000000     18.000000      1.000000         0.000000   \n",
       "25%      861.000000     34.000000      4.000000         1.000000   \n",
       "50%      936.000000     41.000000      5.000000         1.000000   \n",
       "75%     1078.000000     52.000000      5.000000         1.000000   \n",
       "max     1205.000000     99.000000      5.000000         1.000000   \n",
       "\n",
       "       Positive Feedback Count  \n",
       "count             23486.000000  \n",
       "mean                  2.535936  \n",
       "std                   5.702202  \n",
       "min                   0.000000  \n",
       "25%                   0.000000  \n",
       "50%                   1.000000  \n",
       "75%                   3.000000  \n",
       "max                 122.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clothing_reviews.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1996146b935943188a2361023cbb24b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='variables', max=10.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ddb98eb6c04c24a60c2fcecb696da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='correlations', max=6.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7bf1c742b3041caad163b7ec2616d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='interactions [continuous]', max=16.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84964d3f521d4ca28a56ef6976e0af3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='table', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3a8b2f89a24c7eaefd1b8b7d3ae635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='missing', max=4.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f901538edc6d4daf9f75e45b25fa110b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='warnings', max=3.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9eba67e8d648398fcd34e8b8dd2d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='package', max=1.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3a87d71d504e69a02d2d409a3c9354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='build report structure', max=1.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1546660f644ccf9378c7824e695736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(value='Number of va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Report generated with <a href=\"https://github.com/pandas-profiling/pandas-profiling\">pandas-profiling</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pandas Profiling : Really good library to get the overview EDA.\n",
    "profile = ProfileReport(clothing_reviews, title='clothing reviews Profiling Report',minimal=False, html={'style':{'full_width':True}})\n",
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Missing values: \n",
      "Clothing ID                   0\n",
      "Age                           0\n",
      "Title                      3810\n",
      "Review Text                 845\n",
      "Rating                        0\n",
      "Recommended IND               0\n",
      "Positive Feedback Count       0\n",
      "Division Name                14\n",
      "Department Name              14\n",
      "Class Name                   14\n",
      "dtype: int64\n",
      "\n",
      "number of duplicated reviews: 7\n"
     ]
    }
   ],
   "source": [
    "# Finding missing values\n",
    "print(f\"Number of Missing values: \\n{clothing_reviews.isnull().sum()}\\n\")\n",
    "\n",
    "print(f\"number of duplicated reviews: {sum(clothing_reviews[clothing_reviews['Review Text'].notnull()].duplicated(['Review Text'],keep='first'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>1081</td>\n",
       "      <td>42</td>\n",
       "      <td>Beautiful dress, fits poorly</td>\n",
       "      <td>I purchased this and another eva franco dress ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7639</th>\n",
       "      <td>1166</td>\n",
       "      <td>26</td>\n",
       "      <td>Love retailer bathing suits!</td>\n",
       "      <td>Perfect fit and i've gotten so many compliment...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Swim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9447</th>\n",
       "      <td>1022</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love, love these jeans. being short they come ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Jeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10067</th>\n",
       "      <td>1171</td>\n",
       "      <td>26</td>\n",
       "      <td>Love retailer bathing suits!</td>\n",
       "      <td>Perfect fit and i've gotten so many compliment...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Swim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10137</th>\n",
       "      <td>872</td>\n",
       "      <td>43</td>\n",
       "      <td>Love this shirt!</td>\n",
       "      <td>I bought this shirt at the store and after goi...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10708</th>\n",
       "      <td>632</td>\n",
       "      <td>60</td>\n",
       "      <td>Cute cover-up or summer top &amp; shorts!</td>\n",
       "      <td>Lightweight, soft cotton top and shorts. i thi...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Lounge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11074</th>\n",
       "      <td>628</td>\n",
       "      <td>60</td>\n",
       "      <td>Cute cover-up or summer top &amp; shorts!</td>\n",
       "      <td>Lightweight, soft cotton top and shorts. i thi...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Lounge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12526</th>\n",
       "      <td>1081</td>\n",
       "      <td>42</td>\n",
       "      <td>Beautiful dress, fits horribly</td>\n",
       "      <td>I purchased this and another eva franco dress ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13354</th>\n",
       "      <td>393</td>\n",
       "      <td>26</td>\n",
       "      <td>Love retailer bathing suits!</td>\n",
       "      <td>Perfect fit and i've gotten so many compliment...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Swim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14275</th>\n",
       "      <td>879</td>\n",
       "      <td>43</td>\n",
       "      <td>Love this shirt</td>\n",
       "      <td>I bought this shirt at the store and after goi...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16988</th>\n",
       "      <td>993</td>\n",
       "      <td>60</td>\n",
       "      <td>Soft &amp; beautiful!</td>\n",
       "      <td>The sweater and skirt are so pretty! they're r...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Skirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21470</th>\n",
       "      <td>895</td>\n",
       "      <td>60</td>\n",
       "      <td>Soft &amp; beautiful!</td>\n",
       "      <td>The sweater and skirt are so pretty! they're r...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Fine gauge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21888</th>\n",
       "      <td>1022</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love, love these jeans. being short they come ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Jeans</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Clothing ID  Age                                  Title  \\\n",
       "1891          1081   42           Beautiful dress, fits poorly   \n",
       "7639          1166   26           Love retailer bathing suits!   \n",
       "9447          1022   37                                    NaN   \n",
       "10067         1171   26           Love retailer bathing suits!   \n",
       "10137          872   43                       Love this shirt!   \n",
       "10708          632   60  Cute cover-up or summer top & shorts!   \n",
       "11074          628   60  Cute cover-up or summer top & shorts!   \n",
       "12526         1081   42         Beautiful dress, fits horribly   \n",
       "13354          393   26           Love retailer bathing suits!   \n",
       "14275          879   43                        Love this shirt   \n",
       "16988          993   60                      Soft & beautiful!   \n",
       "21470          895   60                      Soft & beautiful!   \n",
       "21888         1022   37                                    NaN   \n",
       "\n",
       "                                             Review Text  Rating  \\\n",
       "1891   I purchased this and another eva franco dress ...       2   \n",
       "7639   Perfect fit and i've gotten so many compliment...       5   \n",
       "9447   Love, love these jeans. being short they come ...       5   \n",
       "10067  Perfect fit and i've gotten so many compliment...       5   \n",
       "10137  I bought this shirt at the store and after goi...       5   \n",
       "10708  Lightweight, soft cotton top and shorts. i thi...       5   \n",
       "11074  Lightweight, soft cotton top and shorts. i thi...       5   \n",
       "12526  I purchased this and another eva franco dress ...       2   \n",
       "13354  Perfect fit and i've gotten so many compliment...       5   \n",
       "14275  I bought this shirt at the store and after goi...       5   \n",
       "16988  The sweater and skirt are so pretty! they're r...       5   \n",
       "21470  The sweater and skirt are so pretty! they're r...       5   \n",
       "21888  Love, love these jeans. being short they come ...       5   \n",
       "\n",
       "       Recommended IND  Positive Feedback Count   Division Name  \\\n",
       "1891                 0                        5         General   \n",
       "7639                 1                        1       Initmates   \n",
       "9447                 1                        0         General   \n",
       "10067                1                        0       Initmates   \n",
       "10137                1                        0  General Petite   \n",
       "10708                1                        8       Initmates   \n",
       "11074                1                        2       Initmates   \n",
       "12526                0                        3         General   \n",
       "13354                1                        0       Initmates   \n",
       "14275                1                        0  General Petite   \n",
       "16988                1                        1         General   \n",
       "21470                1                        5  General Petite   \n",
       "21888                1                        0         General   \n",
       "\n",
       "      Department Name  Class Name  \n",
       "1891          Dresses     Dresses  \n",
       "7639         Intimate        Swim  \n",
       "9447          Bottoms       Jeans  \n",
       "10067        Intimate        Swim  \n",
       "10137            Tops       Knits  \n",
       "10708        Intimate      Lounge  \n",
       "11074        Intimate      Lounge  \n",
       "12526         Dresses     Dresses  \n",
       "13354        Intimate        Swim  \n",
       "14275            Tops       Knits  \n",
       "16988         Bottoms      Skirts  \n",
       "21470            Tops  Fine gauge  \n",
       "21888         Bottoms       Jeans  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duplicate Review text example\n",
    "clothing_reviews[clothing_reviews['Review Text'].notnull()][clothing_reviews[clothing_reviews['Review Text'].notnull()].duplicated(['Review Text'],keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Remove punctuations and stopwords from the text in ‘text’ column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove all the stopwords and words having lengths less than 3\n",
    "import re\n",
    "import string\n",
    "def cleanDataForME(TextData):\n",
    "    TextData = re.sub('[^A-Za-z]+', ' ', TextData)    \n",
    "    word_tokens = word_tokenize(TextData)\n",
    "    filteredText = \"\"\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words and len(w) > 2 and not w.isnumeric() and w not in string.punctuation:\n",
    "            filteredText = filteredText + \" \" + w\n",
    "    \n",
    "    return filteredText.strip()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kishorn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kishorn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = list(get_stop_words('en'))         \n",
    "nltk_words = list(stopwords.words('english'))   \n",
    "stop_words.extend(nltk_words)\n",
    "clothing_reviews['Review Text']=clothing_reviews['Review Text'].astype(str).apply(cleanDataForME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Create two objects X and y. X will be the ' Review Text ' column of clothing_reviews Dataframe and y will be the 'Rating' column. Create a CountVectorizer object and split the data into training and testing sets. Train a MultinomialNB model and Display the confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  11   50  171   43   61]\n",
      " [   6   34  336  147  122]\n",
      " [   6   24  425  359  318]\n",
      " [   0    4  175  662 1233]\n",
      " [   2   10   50  424 4722]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "X=clothing_reviews['Review Text']\n",
    "y=clothing_reviews['Rating']\n",
    "transformer=CountVectorizer(analyzer='word').fit(X) \n",
    "x = transformer.transform(X)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.4, random_state=101)\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train, y_train)\n",
    "predict=nb.predict(x_test)\n",
    "print(confusion_matrix(y_test, predict))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Display the HMM POS tagging on the first 4 rows of ‘Review Text’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\kishorn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('Absolutely', 'RB'),\n",
       "  ('wonderful', 'JJ'),\n",
       "  ('silky', 'JJ'),\n",
       "  ('sexy', 'NN'),\n",
       "  ('comfortable', 'JJ')],\n",
       " [('Love', 'NNP'),\n",
       "  ('dress', 'NN'),\n",
       "  ('sooo', 'NN'),\n",
       "  ('pretty', 'RB'),\n",
       "  ('happened', 'VBD'),\n",
       "  ('find', 'JJ'),\n",
       "  ('store', 'NN'),\n",
       "  ('glad', 'NN'),\n",
       "  ('never', 'RB'),\n",
       "  ('ordered', 'VBD'),\n",
       "  ('online', 'JJ'),\n",
       "  ('petite', 'JJ'),\n",
       "  ('bought', 'VBD'),\n",
       "  ('petite', 'JJ'),\n",
       "  ('love', 'NN'),\n",
       "  ('length', 'NN'),\n",
       "  ('hits', 'VBZ'),\n",
       "  ('little', 'JJ'),\n",
       "  ('knee', 'JJ'),\n",
       "  ('definitely', 'RB'),\n",
       "  ('true', 'JJ'),\n",
       "  ('midi', 'NN'),\n",
       "  ('someone', 'NN'),\n",
       "  ('truly', 'RB'),\n",
       "  ('petite', 'JJ')],\n",
       " [('high', 'JJ'),\n",
       "  ('hopes', 'NNS'),\n",
       "  ('dress', 'VBP'),\n",
       "  ('really', 'RB'),\n",
       "  ('wanted', 'JJ'),\n",
       "  ('work', 'NN'),\n",
       "  ('initially', 'RB'),\n",
       "  ('ordered', 'VBD'),\n",
       "  ('petite', 'JJ'),\n",
       "  ('small', 'JJ'),\n",
       "  ('usual', 'JJ'),\n",
       "  ('size', 'NN'),\n",
       "  ('found', 'VBD'),\n",
       "  ('outrageously', 'RB'),\n",
       "  ('small', 'JJ'),\n",
       "  ('small', 'JJ'),\n",
       "  ('fact', 'NN'),\n",
       "  ('zip', 'NN'),\n",
       "  ('reordered', 'VBD'),\n",
       "  ('petite', 'JJ'),\n",
       "  ('medium', 'NN'),\n",
       "  ('overall', 'JJ'),\n",
       "  ('top', 'JJ'),\n",
       "  ('half', 'NN'),\n",
       "  ('comfortable', 'JJ'),\n",
       "  ('fit', 'JJ'),\n",
       "  ('nicely', 'RB'),\n",
       "  ('bottom', 'JJ'),\n",
       "  ('half', 'NN'),\n",
       "  ('tight', 'JJ'),\n",
       "  ('layer', 'JJ'),\n",
       "  ('several', 'JJ'),\n",
       "  ('somewhat', 'RB'),\n",
       "  ('cheap', 'JJ'),\n",
       "  ('net', 'JJ'),\n",
       "  ('layers', 'NNS'),\n",
       "  ('imo', 'VBP'),\n",
       "  ('major', 'JJ'),\n",
       "  ('design', 'NN'),\n",
       "  ('flaw', 'NN'),\n",
       "  ('net', 'NN'),\n",
       "  ('layer', 'NN'),\n",
       "  ('sewn', 'NN'),\n",
       "  ('directly', 'RB'),\n",
       "  ('zipper', 'IN')],\n",
       " [('love', 'VB'),\n",
       "  ('love', 'NN'),\n",
       "  ('love', 'NN'),\n",
       "  ('jumpsuit', 'NN'),\n",
       "  ('fun', 'NN'),\n",
       "  ('flirty', 'VBP'),\n",
       "  ('fabulous', 'JJ'),\n",
       "  ('every', 'DT'),\n",
       "  ('time', 'NN'),\n",
       "  ('wear', 'JJ'),\n",
       "  ('get', 'NN'),\n",
       "  ('nothing', 'NN'),\n",
       "  ('great', 'JJ'),\n",
       "  ('compliments', 'NNS')]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk_data = []\n",
    "review_data = clothing_reviews.iloc[:4]['Review Text']\n",
    "for sentence in review_data:\n",
    "    sentence = nltk.sent_tokenize(sentence)\n",
    "    for sent in sentence:\n",
    "        nltk_data.append(nltk.pos_tag(nltk.word_tokenize(sent)))\n",
    "nltk_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n",
      "[[('Absolutely', 'RB'), ('wonderful', 'JJ'), ('silky', 'JJ'), ('sexy', 'NN'), ('comfortable', 'JJ')], [('Love', 'NNP'), ('dress', 'NN'), ('sooo', 'NN'), ('pretty', 'RB'), ('happened', 'VBD'), ('find', 'JJ'), ('store', 'NN'), ('glad', 'NN'), ('never', 'RB'), ('ordered', 'VBD'), ('online', 'JJ'), ('petite', 'JJ'), ('bought', 'VBD'), ('petite', 'JJ'), ('love', 'NN'), ('length', 'NN'), ('hits', 'VBZ'), ('little', 'JJ'), ('knee', 'JJ'), ('definitely', 'RB'), ('true', 'JJ'), ('midi', 'NN'), ('someone', 'NN'), ('truly', 'RB'), ('petite', 'JJ')], [('high', 'JJ'), ('hopes', 'NNS'), ('dress', 'VBP'), ('really', 'RB'), ('wanted', 'JJ'), ('work', 'NN'), ('initially', 'RB'), ('ordered', 'VBD'), ('petite', 'JJ'), ('small', 'JJ'), ('usual', 'JJ'), ('size', 'NN'), ('found', 'VBD'), ('outrageously', 'RB'), ('small', 'JJ'), ('small', 'JJ'), ('fact', 'NN'), ('zip', 'NN'), ('reordered', 'VBD'), ('petite', 'JJ'), ('medium', 'NN'), ('overall', 'JJ'), ('top', 'JJ'), ('half', 'NN'), ('comfortable', 'JJ'), ('fit', 'JJ'), ('nicely', 'RB'), ('bottom', 'JJ'), ('half', 'NN'), ('tight', 'JJ'), ('layer', 'JJ'), ('several', 'JJ'), ('somewhat', 'RB'), ('cheap', 'JJ'), ('net', 'JJ'), ('layers', 'NNS'), ('imo', 'VBP'), ('major', 'JJ'), ('design', 'NN'), ('flaw', 'NN'), ('net', 'NN'), ('layer', 'NN'), ('sewn', 'NN'), ('directly', 'RB'), ('zipper', 'IN')]]\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train and test\n",
    "import random\n",
    "random.seed(1234)\n",
    "train_set, test_set = train_test_split(nltk_data,test_size=0.05)\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "print(train_set[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting list of tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Absolutely',\n",
       " 'wonderful',\n",
       " 'silky',\n",
       " 'sexy',\n",
       " 'comfortable',\n",
       " 'Love',\n",
       " 'dress',\n",
       " 'sooo',\n",
       " 'pretty',\n",
       " 'happened']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokens \n",
    "tokens = [pair[0] for pair in train_tagged_words]\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "# vocabulary\n",
    "from nltk.tokenize import word_tokenize\n",
    "V = set(tokens)\n",
    "print(len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of tags\n",
    "T = set([pair[1] for pair in train_tagged_words])\n",
    "len(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'VBP', 'VBD', 'NNP', 'NN', 'VBZ', 'RB', 'IN', 'NNS', 'JJ'}\n"
     ]
    }
   ],
   "source": [
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  POS Tagging Algorithm - HMM\n",
    "### Emission Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing P(w/t) and storing in T x V matrix\n",
    "t = len(T)\n",
    "v = len(V)\n",
    "w_given_t = np.zeros((t, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
    "\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(T), len(T)), dtype='float32')\n",
    "for i, t1 in enumerate(list(T)):\n",
    "    for j, t2 in enumerate(list(T)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.5       , 0.        , 0.        , 0.5       ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.16666667, 0.        , 0.        , 0.8333333 ],\n",
       "       [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.0952381 , 0.        , 0.42857143, 0.04761905,\n",
       "        0.23809524, 0.        , 0.        , 0.1904762 ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.27272728, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.09090909, 0.        , 0.6363636 ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.03333334, 0.03333334, 0.36666667, 0.        ,\n",
       "        0.1       , 0.        , 0.06666667, 0.4       ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(T), index=list(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VBP</th>\n",
       "      <th>VBD</th>\n",
       "      <th>NNP</th>\n",
       "      <th>NN</th>\n",
       "      <th>VBZ</th>\n",
       "      <th>RB</th>\n",
       "      <th>IN</th>\n",
       "      <th>NNS</th>\n",
       "      <th>JJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VBP</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VBD</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNP</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VBZ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RB</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNS</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JJ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     VBP       VBD       NNP        NN       VBZ        RB        IN  \\\n",
       "VBP  0.0  0.000000  0.000000  0.000000  0.000000  0.500000  0.000000   \n",
       "VBD  0.0  0.000000  0.000000  0.000000  0.000000  0.166667  0.000000   \n",
       "NNP  0.0  0.000000  0.000000  1.000000  0.000000  0.000000  0.000000   \n",
       "NN   0.0  0.095238  0.000000  0.428571  0.047619  0.238095  0.000000   \n",
       "VBZ  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "RB   0.0  0.272727  0.000000  0.000000  0.000000  0.000000  0.090909   \n",
       "IN   0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "NNS  1.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "JJ   0.0  0.033333  0.033333  0.366667  0.000000  0.100000  0.000000   \n",
       "\n",
       "          NNS        JJ  \n",
       "VBP  0.000000  0.500000  \n",
       "VBD  0.000000  0.833333  \n",
       "NNP  0.000000  0.000000  \n",
       "NN   0.000000  0.190476  \n",
       "VBZ  0.000000  1.000000  \n",
       "RB   0.000000  0.636364  \n",
       "IN   0.000000  0.000000  \n",
       "NNS  0.000000  0.000000  \n",
       "JJ   0.066667  0.400000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Parse the first 4 rows of ‘Review Text’ using Viterbi Parser [Use toy_pcfg1 and toy_pcfg2 to get the probabilistic context free grammars; use the PCFG suitable for each sentence] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time\n",
    "from nltk import tokenize\n",
    "from nltk.parse import ViterbiParser\n",
    "from nltk.grammar import toy_pcfg1, toy_pcfg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "        (clothing_reviews.iloc[1]['Review Text'], toy_pcfg1),\n",
    "        (clothing_reviews.iloc[2]['Review Text'], toy_pcfg2),\n",
    "    (clothing_reviews.iloc[3]['Review Text'], toy_pcfg1),\n",
    "    (clothing_reviews.iloc[4]['Review Text'], toy_pcfg2),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1: Love dress sooo pretty happened find store glad never ordered online petite bought petite love length hits little knee definitely true midi someone truly petite\n",
      "     <Grammar with 17 productions>\n",
      "\n",
      "\n",
      "sent: Love dress sooo pretty happened find store glad never ordered online petite bought petite love length hits little knee definitely true midi someone truly petite\n",
      "parser: <ViterbiParser for <Grammar with 17 productions>>\n",
      "grammar: Grammar with 17 productions (start state = S)\n",
      "    S -> NP VP [1.0]\n",
      "    NP -> Det N [0.5]\n",
      "    NP -> NP PP [0.25]\n",
      "    NP -> 'John' [0.1]\n",
      "    NP -> 'I' [0.15]\n",
      "    Det -> 'the' [0.8]\n",
      "    Det -> 'my' [0.2]\n",
      "    N -> 'man' [0.5]\n",
      "    N -> 'telescope' [0.5]\n",
      "    VP -> VP PP [0.1]\n",
      "    VP -> V NP [0.7]\n",
      "    VP -> V [0.2]\n",
      "    V -> 'ate' [0.35]\n",
      "    V -> 'saw' [0.65]\n",
      "    PP -> P NP [1.0]\n",
      "    P -> 'with' [0.61]\n",
      "    P -> 'under' [0.39]\n",
      "  2: high hopes dress really wanted work initially ordered petite small usual size found outrageously small small fact zip reordered petite medium overall top half comfortable fit nicely bottom half tight layer several somewhat cheap net layers imo major design flaw net layer sewn directly zipper\n",
      "     <Grammar with 23 productions>\n",
      "\n",
      "\n",
      "sent: high hopes dress really wanted work initially ordered petite small usual size found outrageously small small fact zip reordered petite medium overall top half comfortable fit nicely bottom half tight layer several somewhat cheap net layers imo major design flaw net layer sewn directly zipper\n",
      "parser: <ViterbiParser for <Grammar with 23 productions>>\n",
      "grammar: Grammar with 23 productions (start state = S)\n",
      "    S -> NP VP [1.0]\n",
      "    VP -> V NP [0.59]\n",
      "    VP -> V [0.4]\n",
      "    VP -> VP PP [0.01]\n",
      "    NP -> Det N [0.41]\n",
      "    NP -> Name [0.28]\n",
      "    NP -> NP PP [0.31]\n",
      "    PP -> P NP [1.0]\n",
      "    V -> 'saw' [0.21]\n",
      "    V -> 'ate' [0.51]\n",
      "    V -> 'ran' [0.28]\n",
      "    N -> 'boy' [0.11]\n",
      "    N -> 'cookie' [0.12]\n",
      "    N -> 'table' [0.13]\n",
      "    N -> 'telescope' [0.14]\n",
      "    N -> 'hill' [0.5]\n",
      "    Name -> 'Jack' [0.52]\n",
      "    Name -> 'Bob' [0.48]\n",
      "    P -> 'with' [0.61]\n",
      "    P -> 'under' [0.39]\n",
      "    Det -> 'the' [0.41]\n",
      "    Det -> 'a' [0.31]\n",
      "    Det -> 'my' [0.28]\n",
      "  3: love love love jumpsuit fun flirty fabulous every time wear get nothing great compliments\n",
      "     <Grammar with 17 productions>\n",
      "\n",
      "\n",
      "sent: love love love jumpsuit fun flirty fabulous every time wear get nothing great compliments\n",
      "parser: <ViterbiParser for <Grammar with 17 productions>>\n",
      "grammar: Grammar with 17 productions (start state = S)\n",
      "    S -> NP VP [1.0]\n",
      "    NP -> Det N [0.5]\n",
      "    NP -> NP PP [0.25]\n",
      "    NP -> 'John' [0.1]\n",
      "    NP -> 'I' [0.15]\n",
      "    Det -> 'the' [0.8]\n",
      "    Det -> 'my' [0.2]\n",
      "    N -> 'man' [0.5]\n",
      "    N -> 'telescope' [0.5]\n",
      "    VP -> VP PP [0.1]\n",
      "    VP -> V NP [0.7]\n",
      "    VP -> V [0.2]\n",
      "    V -> 'ate' [0.35]\n",
      "    V -> 'saw' [0.65]\n",
      "    PP -> P NP [1.0]\n",
      "    P -> 'with' [0.61]\n",
      "    P -> 'under' [0.39]\n",
      "  4: This shirt flattering due adjustable front tie perfect length wear leggings sleeveless pairs well cardigan love shirt\n",
      "     <Grammar with 23 productions>\n",
      "\n",
      "\n",
      "sent: This shirt flattering due adjustable front tie perfect length wear leggings sleeveless pairs well cardigan love shirt\n",
      "parser: <ViterbiParser for <Grammar with 23 productions>>\n",
      "grammar: Grammar with 23 productions (start state = S)\n",
      "    S -> NP VP [1.0]\n",
      "    VP -> V NP [0.59]\n",
      "    VP -> V [0.4]\n",
      "    VP -> VP PP [0.01]\n",
      "    NP -> Det N [0.41]\n",
      "    NP -> Name [0.28]\n",
      "    NP -> NP PP [0.31]\n",
      "    PP -> P NP [1.0]\n",
      "    V -> 'saw' [0.21]\n",
      "    V -> 'ate' [0.51]\n",
      "    V -> 'ran' [0.28]\n",
      "    N -> 'boy' [0.11]\n",
      "    N -> 'cookie' [0.12]\n",
      "    N -> 'table' [0.13]\n",
      "    N -> 'telescope' [0.14]\n",
      "    N -> 'hill' [0.5]\n",
      "    Name -> 'Jack' [0.52]\n",
      "    Name -> 'Bob' [0.48]\n",
      "    P -> 'with' [0.61]\n",
      "    P -> 'under' [0.39]\n",
      "    Det -> 'the' [0.41]\n",
      "    Det -> 'a' [0.31]\n",
      "    Det -> 'my' [0.28]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    print(\"%3s: %s\" % (i + 1, data[i][0]))\n",
    "    print(\"     %r\" % data[i][1])\n",
    "    print()\n",
    "    sent, grammar = data[i]\n",
    "    # Tokenize the sentence.\n",
    "    tokens = sent.split()\n",
    "    parser = ViterbiParser(grammar)\n",
    "    all_parses = {}\n",
    "    parses = all_parses.keys()\n",
    "    print(\"\\nsent: %s\\nparser: %s\\ngrammar: %s\" % (sent, parser, grammar))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
